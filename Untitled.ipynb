{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "from statistics import mean, stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(xTrain, xTest):\n",
    "    std_scale = preprocessing.StandardScaler(with_mean=False)\n",
    "    cols = list(xTrain.columns)\n",
    "    xTrain = std_scale.fit_transform(xTrain)\n",
    "    xTest = std_scale.transform(xTest)\n",
    "    xTrain = pd.DataFrame(xTrain, columns=cols)\n",
    "    xTest = pd.DataFrame(xTest, columns=cols)\n",
    "    return xTrain, xTest\n",
    "\n",
    "def extract_features(df):\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    df.insert(loc=0, column='dt_year', value=df['datetime'].dt.year)\n",
    "    df.insert(loc=0, column='dt_month', value=df['datetime'].dt.month)\n",
    "    df.insert(loc=0, column='dt_day', value=df['datetime'].dt.day)\n",
    "    df.insert(loc=0, column='dt_dayofweek', value=df['datetime'].dt.dayofweek)\n",
    "    df.insert(loc=0, column='dt_hour', value=df['datetime'].dt.hour)\n",
    "    df = df.drop(columns=['datetime'])\n",
    "    return df\n",
    "\n",
    "# use pearson correlation to remove redundant features and features with nan correlation to stock price change\n",
    "def pearson_graph(dfx, dfy):\n",
    "    matrix = dfx.to_numpy()\n",
    "    matrix = np.hstack((dfy['stock_change'].to_numpy()[:,np.newaxis], matrix))\n",
    "    matrix = matrix.transpose()\n",
    "    corr = np.ma.corrcoef(matrix)\n",
    "    corr = np.ma.getdata(corr)\n",
    "    columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "    for i in range(corr.shape[0]):\n",
    "        if pd.isnull(corr[0,i]):\n",
    "            if columns[i]:\n",
    "                columns[i] = False\n",
    "        for j in range(i+1, corr.shape[0]):\n",
    "            if corr[i,j] >= 0.9:\n",
    "                if columns[j]:\n",
    "                    columns[j] = False\n",
    "    selected_columns = dfx.columns[columns[1:]]\n",
    "    return selected_columns, corr\n",
    "\n",
    "def process(xTrain, yTrain, xTest, yTest):\n",
    "    xTrain, xTest = normalization(xTrain, xTest)\n",
    "    selected_columns, corr = pearson_graph(xTrain, yTrain)\n",
    "    xTrain = xTrain[selected_columns[1:]]\n",
    "    xTest = xTest[selected_columns[1:]]\n",
    "    return xTrain.to_numpy(), yTrain.to_numpy(), xTest.to_numpy(), yTest.to_numpy()\n",
    "\n",
    "def get_csv():\n",
    "    x = pd.read_csv('X.csv')\n",
    "    y = pd.read_csv('Y.csv')\n",
    "    # extract features of datetime column\n",
    "    x = extract_features(x)\n",
    "    # drop datetime column from y data\n",
    "    y = y.drop(columns=['datetime'])\n",
    "    return x, y\n",
    "\n",
    "def kfold_cv(x, y, model):\n",
    "    nested_train_scores = list()\n",
    "    nested_test_scores = list()\n",
    "\n",
    "    outer_cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    for train_index, test_index in tqdm(outer_cv.split(x)):\n",
    "        # split data\n",
    "        xTrain = x.iloc[train_index]\n",
    "        xTest = x.iloc[test_index]\n",
    "        yTrain = y.iloc[train_index]\n",
    "        yTest = y.iloc[test_index]\n",
    "        xTrain, yTrain, xTest, yTest = process(xTrain, yTrain, xTest, yTest)\n",
    "\n",
    "        # PCA (number of components chosen such that the amount of variance \n",
    "        # that needs to be explained is greater than the percentage specified by n_components)\n",
    "        sklearn_PCA = PCA(n_components=0.95, svd_solver='full')\n",
    "        xTrain = sklearn_PCA.fit_transform(xTrain)\n",
    "        xTest = sklearn_PCA.transform(xTest)\n",
    "        # xTrain, yTrain, xTest, yTest = df_to_numpy(xTrain, yTrain, xTest, yTest)\n",
    "\n",
    "        md = model.fit(xTrain, yTrain)\n",
    "\n",
    "        # Train Score\n",
    "        r2 = model.score(xTrain, yTrain)\n",
    "        nested_train_scores.append(r2)\n",
    "\n",
    "        # Test Score\n",
    "        r2 = model.score(xTest, yTest)\n",
    "        nested_test_scores.append(r2)\n",
    "    return nested_train_scores, nested_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_csv()\n",
    "lr = LinearRegression()\n",
    "lasr = Lasso(alpha=0.1)\n",
    "ridr = Ridge(alpha=60)\n",
    "elr = ElasticNet(alpha=0.1, l1_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:47, 21.55s/it]\n",
      "5it [01:54, 22.93s/it]\n",
      "5it [02:03, 24.70s/it]\n",
      "5it [02:12, 26.47s/it]\n"
     ]
    }
   ],
   "source": [
    "lr_train, lr_test = kfold_cv(x, y, lr)\n",
    "lasr_train, lasr_test = kfold_cv(x, y, lasr)\n",
    "ridr_train, ridr_test = kfold_cv(x, y, ridr)\n",
    "elr_train, elr_test = kfold_cv(x, y, elr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation mean R^2 scores with PCA\n",
      "Linear Regression (Closed):\n",
      "[train] 0.8391422061271094 +/- 0.014876450428982392\n",
      "[test] 0.30448089805210765 +/- 0.12653328431896188\n",
      "Lasso Regression:\n",
      "[train] 0.8089311903357289 +/- 0.014478705103926483\n",
      "[test] 0.32518945304761765 +/- 0.10499498635086156\n",
      "Ridge Regression:\n",
      "[train] 0.8388392256079907 +/- 0.014864145355886971\n",
      "[test] 0.3106787958784869 +/- 0.12438243400522321\n",
      "Elastic Net:\n",
      "[train] 0.8379759100466714 +/- 0.01484850971614257\n",
      "[test] 0.31460748136912325 +/- 0.12194933646300489\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross validation mean R^2 scores with PCA\")\n",
    "print(\"Linear Regression (Closed):\")\n",
    "print(\"[train] {} +/- {}\".format(mean(lr_train), stdev(lr_train)))\n",
    "print(\"[test] {} +/- {}\".format(mean(lr_test), stdev(lr_test)))\n",
    "print(\"Lasso Regression:\")\n",
    "print(\"[train] {} +/- {}\".format(mean(lasr_train), stdev(lasr_train)))\n",
    "print(\"[test] {} +/- {}\".format(mean(lasr_test), stdev(lasr_test)))\n",
    "print(\"Ridge Regression:\")\n",
    "print(\"[train] {} +/- {}\".format(mean(ridr_train), stdev(ridr_train)))\n",
    "print(\"[test] {} +/- {}\".format(mean(ridr_test), stdev(ridr_test)))\n",
    "print(\"Elastic Net:\")\n",
    "print(\"[train] {} +/- {}\".format(mean(elr_train), stdev(elr_train)))\n",
    "print(\"[test] {} +/- {}\".format(mean(elr_test), stdev(elr_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
